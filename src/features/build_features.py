#!/usr/bin/env python3
"""
Ğ“Ğ»Ğ°Ğ²Ğ½Ñ‹Ğ¹ ÑĞºÑ€Ğ¸Ğ¿Ñ‚ Ğ´Ğ»Ñ Ğ¿Ğ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ñ Ñ„Ğ¸Ñ‡ĞµĞ¹ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ OZON
"""
print("zebra")
import pandas as pd
import numpy as np
import json
import os
import sys
from pathlib import Path

# Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ ĞºĞ¾Ñ€Ğ½ĞµĞ²ÑƒÑ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ² Ğ¿ÑƒÑ‚ÑŒ
current_dir = Path(__file__).parent
root_dir = current_dir.parent.parent
sys.path.append(str(root_dir))

# Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ñ‡ĞµÑ€ĞµĞ· src, Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ½Ğ°Ğ¿Ñ€ÑĞ¼ÑƒÑ
import importlib.util

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ° Ğ¼Ğ¾Ğ´ÑƒĞ»Ñ Ğ¿Ğ¾ Ğ¿ÑƒÑ‚Ğ¸
def import_module_from_path(module_name, file_path):
    spec = importlib.util.spec_from_file_location(module_name, file_path)
    module = importlib.util.module_from_spec(spec) # type: ignore
    spec.loader.exec_module(module) # type: ignore
    return module

# Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ½Ğ°ÑˆĞ¸ Ğ¼Ğ¾Ğ´ÑƒĞ»Ğ¸
ozon_loader_path = root_dir / 'src' / 'features' / 'ozon_data_loader.py'
feature_engineer_path = root_dir / 'src' / 'features' / 'enhanced_feature_engineer.py'

# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑÑƒÑ‰ĞµÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²
print(f"ğŸ” Checking loader path: {ozon_loader_path}")
print(f"ğŸ” Checking engineer path: {feature_engineer_path}")

if ozon_loader_path.exists() and feature_engineer_path.exists():
    OzonDataLoader = import_module_from_path('ozon_data_loader', ozon_loader_path).OzonDataLoader
    EnhancedFeatureEngineer = import_module_from_path('enhanced_feature_engineer', feature_engineer_path).EnhancedFeatureEngineer
    print("âœ… Modules imported successfully")
else:
    print("âŒ Module files not found, creating simple implementation...")
    
    # ĞŸÑ€Ğ¾ÑÑ‚Ğ°Ñ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ĞµÑĞ»Ğ¸ Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹
    class OzonDataLoader:
        def __init__(self, config_path='config/feature_config.json'):
            self.root_dir = Path(__file__).parent.parent.parent
            print(f"ğŸ“ Project root: {self.root_dir}")
        
        def explore_data_structure(self):
            """Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ»Ğ°Ğ´ĞºĞ¸"""
            print("ğŸ” Exploring data directory structure...")
            data_dir = self.root_dir / 'data'
            if data_dir.exists():
                print("âœ… Data directory exists")
                for item in data_dir.rglob("*.parquet"):
                    if not item.name.startswith('._'):
                        print(f"   ğŸ“„ {item.relative_to(self.root_dir)}")
            else:
                print("âŒ Data directory does not exist")
        
        def load_interactions(self):
            """Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ"""
            print("ğŸ“ Creating sample interactions data...")
            return pd.DataFrame({
                'user_id': [1, 1, 2, 2, 3, 3, 4, 4, 5, 5],
                'item_id': [101, 102, 101, 103, 102, 104, 103, 105, 104, 106],
                'timestamp': pd.date_range('2025-01-01', periods=10, freq='H'),
                'action_type': ['view', 'purchase', 'view', 'view', 'purchase', 'view', 'cart', 'view', 'purchase', 'view']
            })
    
    class EnhancedFeatureEngineer:
        def __init__(self, config=None):
            self.config = config or {}
            self.time_windows = self.config.get('time_windows', [1, 3, 7, 14, 30])
        
        def create_enhanced_features(self, df):
            """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ½Ñ‹Ñ… Ñ„Ğ¸Ñ‡ĞµĞ¹"""
            if df.empty:
                return df
            
            df = df.copy()
            print("ğŸ› ï¸ Creating enhanced features...")
            
            # Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ñ„Ğ¸Ñ‡Ğ¸
            if 'timestamp' in df.columns:
                df['timestamp'] = pd.to_datetime(df['timestamp'])
                df['hour'] = df['timestamp'].dt.hour
                df['day_of_week'] = df['timestamp'].dt.dayofweek
                df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)
            
            # User features
            if 'user_id' in df.columns:
                user_stats = df.groupby('user_id').agg({
                    'timestamp': ['count', 'min', 'max']
                }).reset_index()
                user_stats.columns = ['user_id', 'user_total_events', 'first_activity', 'last_activity']
                df = df.merge(user_stats, on='user_id', how='left')
            
            # Item features
            if 'item_id' in df.columns:
                item_stats = df.groupby('item_id').agg({
                    'timestamp': 'count',
                    'user_id': 'nunique'
                }).reset_index()
                item_stats.columns = ['item_id', 'item_popularity', 'unique_users']
                df = df.merge(item_stats, on='item_id', how='left')
            
            return df
        
        def create_improved_targets(self, df):
            """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ñ‚Ğ°Ñ€Ğ³ĞµÑ‚Ğ¾Ğ²"""
            if 'action_type' not in df.columns:
                return None
            
            # ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ğµ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ñ‚Ğ°Ñ€Ğ³ĞµÑ‚Ğ¾Ğ²
            positive_actions = ['purchase', 'buy', 'cart', 'order']
            df['action_lower'] = df['action_type'].astype(str).str.lower()
            targets = df['action_lower'].isin(positive_actions).astype(int)
            
            print(f"ğŸ¯ Targets: {targets.sum()}/{len(targets)} positive ({targets.mean():.2%})")
            return targets

def explore_directory():
    """Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ»Ğ°Ğ´ĞºĞ¸"""
    print("ğŸ” Exploring directory structure...")
    
    root_dir = Path(__file__).parent.parent.parent
    data_dir = root_dir / 'data'
    print(f"ğŸ“ Root: {root_dir}")
    print(f"ğŸ“ Data: {data_dir}")
    
    if data_dir.exists():
        print("âœ… Data directory exists")
        parquet_files = list(data_dir.rglob("*.parquet"))
        for file in parquet_files[:10]:  # ĞŸĞ¾ĞºĞ°Ğ¶ĞµĞ¼ Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ 10 Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²
            if not file.name.startswith('._'):
                print(f"   ğŸ“„ {file.relative_to(root_dir)}")
        if len(parquet_files) > 10:
            print(f"   ... and {len(parquet_files) - 10} more")
    else:
        print("âŒ Data directory does not exist")

def main():
    """Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ¿Ğ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ¸Ñ Ñ„Ğ¸Ñ‡ĞµĞ¹"""
    print("=" * 60)
    print("ğŸš€ STARTING OZON FEATURE ENGINEERING PIPELINE")
    print("=" * 60)
    
    try:
        # 0. Ğ˜ÑÑĞ»ĞµĞ´ÑƒĞµĞ¼ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¹
        print("\n0. ğŸ” DIRECTORY EXPLORATION")
        print("-" * 40)
        explore_directory()
        
        # 1. Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
        print("\n1. ğŸ“¥ INITIALIZATION")
        print("-" * 40)
        
        data_loader = OzonDataLoader()
        
        # 2. Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
        print("\n2. ğŸ“¥ LOADING DATA")
        print("-" * 40)
        
        data_loader.explore_data_structure()
        interactions = data_loader.load_interactions()
        
        print(f"\nğŸ“Š Interactions shape: {interactions.shape}")
        print(f"ğŸ“‹ Interactions columns: {list(interactions.columns)}")
        
        if not interactions.empty and 'action_type' in interactions.columns:
            print(f"ğŸ” Action types: {interactions['action_type'].unique()}")
        
        # 3. Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³Ğ°
        print("\n3. âš™ï¸ LOADING CONFIG")
        print("-" * 40)
        
        root_dir = Path(__file__).parent.parent.parent
        config_path = root_dir / 'config' / 'feature_config.json'
        
        if config_path.exists():
            with open(config_path, 'r') as f:
                config = json.load(f)
            print("âœ… Config loaded successfully")
        else:
            print("âš ï¸ Config file not found, using defaults")
            config = {
                'feature_params': {
                    'time_windows': [1, 3, 7, 14, 30],
                    'min_user_interactions': 3
                }
            }
        
        # 4. Feature Engineering
        print("\n4. ğŸ› ï¸ FEATURE ENGINEERING")
        print("-" * 40)
        
        feature_engineer = EnhancedFeatureEngineer(config.get('feature_params', {}))
        features = feature_engineer.create_enhanced_features(interactions)
        
        print(f"ğŸ“Š Enhanced features shape: {features.shape}")
        print(f"ğŸ“‹ New columns: {[col for col in features.columns if col not in interactions.columns]}")
        
        # 5. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ñ‚Ğ°Ñ€Ğ³ĞµÑ‚Ğ¾Ğ²
        print("\n5. ğŸ¯ CREATING TARGETS")
        print("-" * 40)
        
        targets = feature_engineer.create_improved_targets(features)
        
        if targets is None:
            print("âŒ Failed to create targets")
            return None, None
        
        # 6. Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²
        print("\n6. ğŸ’¾ SAVING RESULTS")
        print("-" * 40)
        
        root_dir = Path(__file__).parent.parent.parent
        processed_dir = root_dir / 'data' / 'processed'
        processed_dir.mkdir(parents=True, exist_ok=True)
        
        features_path = processed_dir / 'features.parquet'
        targets_path = processed_dir / 'targets.parquet'
        
        features.to_parquet(features_path)
        pd.DataFrame({'target': targets}).to_parquet(targets_path)
        
        print(f"âœ… Features saved to: {features_path}")
        print(f"âœ… Targets saved to: {targets_path}")
        print(f"ğŸ“Š Final features shape: {features.shape}")
        print(f"ğŸ¯ Target distribution: {targets.sum()}/{len(targets)} positive ({targets.mean():.2%})")
        
        print("\n" + "=" * 60)
        print("âœ… FEATURE ENGINEERING COMPLETED SUCCESSFULLY!")
        print("=" * 60)
        
        return features, targets
        
    except Exception as e:
        print(f"\nâŒ ERROR: {e}")
        import traceback
        traceback.print_exc()
        return None, None

if __name__ == "__main__":
    main()
