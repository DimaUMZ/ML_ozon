import pandas as pd
import numpy as np
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from utils.config import config

class ItemFeatureEngineer:
    def __init__(self):
        self.params = config.get_feature_params()
    
    def calculate_item_popularity(self, df, item_col='item_id', 
                                action_col='action', timestamp_col='timestamp'):
        """ÐŸÐ¾Ð¿ÑƒÐ»ÑÑ€Ð½Ð¾ÑÑ‚ÑŒ Ñ‚Ð¾Ð²Ð°Ñ€Ð° Ð² Ñ€Ð°Ð·Ð½Ñ‹Ðµ Ð¿ÐµÑ€Ð¸Ð¾Ð´Ñ‹"""
        df = df.copy()
        df[timestamp_col] = pd.to_datetime(df[timestamp_col])
        
        item_popularity = {}
        current_time = pd.Timestamp.now()
        
        for window in self.params['time_windows']:
            # ÐŸÐ¾Ð¿ÑƒÐ»ÑÑ€Ð½Ð¾ÑÑ‚ÑŒ Ð·Ð° Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ N Ð´Ð½ÐµÐ¹
            recent_data = df[
                df[timestamp_col] > (current_time - pd.Timedelta(days=window))
            ]
            popularity = recent_data[item_col].value_counts()
            item_popularity[f'item_popularity_{window}d'] = popularity
        
        return item_popularity
    
    def calculate_item_engagement_metrics(self, df, item_col='item_id', action_col='action'):
        """ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð²Ð¾Ð²Ð»ÐµÑ‡ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸ Ð´Ð»Ñ Ñ‚Ð¾Ð²Ð°Ñ€Ð¾Ð²"""
        engagement_metrics = df.groupby([item_col, action_col]).size().unstack(fill_value=0)
        
        # CTR-like Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°
        if 'view' in engagement_metrics.columns and 'purchase' in engagement_metrics.columns:
            engagement_metrics['view_to_purchase_ratio'] = (
                engagement_metrics['purchase'] / engagement_metrics['view']
            ).replace([np.inf, -np.inf], 0).fillna(0)
        
        return engagement_metrics
    
    def calculate_item_temporal_patterns(self, df, item_col='item_id', timestamp_col='timestamp'):
        """Ð’Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ñ‹ Ñ‚Ð¾Ð²Ð°Ñ€Ð¾Ð²"""
        df = df.copy()
        df[timestamp_col] = pd.to_datetime(df[timestamp_col])
        
        df['hour'] = df[timestamp_col].dt.hour
        df['day_of_week'] = df[timestamp_col].dt.dayofweek
        
        # ÐŸÐ¾Ð¿ÑƒÐ»ÑÑ€Ð½Ð¾ÑÑ‚ÑŒ Ð¿Ð¾ Ñ‡Ð°ÑÐ°Ð¼ (Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð¾Ð²Ð°Ð½Ð½Ð°Ñ)
        hour_popularity = df.groupby([item_col, 'hour']).size().unstack(fill_value=0)
        hour_popularity = hour_popularity.div(hour_popularity.sum(axis=1), axis=0)
        
        return hour_popularity

    def expand_items_attributes(self, df):
        """Ð Ð°Ð·Ð±Ð¸ÐµÐ½Ð¸Ðµ attributes Ð² items Ð½Ð° Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²"""
        
        if df.empty:
            print("âŒ No data to expand attributes")
            return pd.DataFrame()
        
        if 'attributes' not in df.columns:
            print("âš ï¸ Attributes expansion skipped - no 'attributes' column found")
            return df
        
        print(f"ðŸ“Š Initial data for attributes expansion: {df.shape}")
        print(f"ðŸ“‹ Columns before expansion: {list(df.columns)}")
        
        def process_attributes(attr_list):
            if isinstance(attr_list, str):
                try:
                    if attr_list.startswith('['):
                        attr_list = ast.literal_eval(attr_list)
                    else:
                        attr_list = attr_list.replace('null', 'None')
                        attr_list = ast.literal_eval(attr_list)
                except:
                    return {}
            
            result = {}
            for attr in attr_list:
                name = attr.get('attribute_name')
                value = attr.get('attribute_value')
                if name:
                    if name in result:
                        if isinstance(result[name], list):
                            result[name].append(value)
                        else:
                            result[name] = [result[name], value]
                    else:
                        result[name] = value
            return result
        
        # ÐŸÑ€Ð¸Ð¼ÐµÐ½ÑÐµÐ¼ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑŽ Ðº ÐºÐ°Ð¶Ð´Ð¾Ð¹ ÑÑ‚Ñ€Ð¾ÐºÐµ
        expanded_data = df['attributes'].apply(process_attributes)
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ DataFrame Ð¸Ð· ÑÐ»Ð¾Ð²Ð°Ñ€ÐµÐ¹
        expanded_df = pd.json_normalize(expanded_data)
        
        # ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÑÐµÐ¼ Ñ Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¼ DataFrame
        result_df = pd.concat([df.drop('attributes', axis=1), expanded_df], axis=1)
        
        # Ð£Ð´Ð°Ð»ÑÐµÐ¼ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¸ Ñ ÑÐ»Ð¸ÑˆÐºÐ¾Ð¼ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ð¼ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾Ð¼ Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ¾Ð² (>30%)
        threshold = 0.3  # ÐŸÐ¾Ñ€Ð¾Ð³: Ð±Ð¾Ð»ÑŒÑˆÐµ 30% Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ¾Ð²
        missing_ratio = result_df.isnull().mean()
        columns_to_drop = missing_ratio[missing_ratio > threshold].index.tolist()
        
        if columns_to_drop:
            print(f"ðŸ—‘ï¸ Removing columns with >{threshold*100:.0f}% missing values: {columns_to_drop}")
            result_df = result_df.drop(columns=columns_to_drop)
        
        print(f"ðŸ“Š After attributes expansion: {result_df.shape}")
        print(f"ðŸ“‹ Columns after expansion: {list(result_df.columns)}")
        
        # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ð¾ Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ°Ð¼
        if not result_df.empty:
            missing_stats = result_df.isnull().mean().sort_values(ascending=False)
            high_missing = missing_stats[missing_stats > 0]
            if not high_missing.empty:
                print("ðŸ“ˆ Missing values statistics (columns with missing values):")
                for col, ratio in high_missing.items():
                    print(f"   - {col}: {ratio:.1%} missing")
        
        return result_df
